<!DOCTYPE HTML>
<html lang="en"><head>

    <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-L4F2WV7NRX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-L4F2WV7NRX');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zixuan Ke</title>

  <meta name="author" content="Zixuan Ke">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zixuan Ke</name>
              </p>
              <p>I am a 4th-year Ph.D. student at the <a href="https://www.cs.uic.edu/">University of Illinois, Chicago</a>, where I am advised by Prof. <a href="https://www.cs.uic.edu/~liub/">Bing Liu</a>.
                Prior to that, I received my M.Sc. in Computer Science from the <a href="https://www.cs.utdallas.edu/">University of Texas, Dallas</a> and was advised by Prof. <a href="https://www.hlt.utdallas.edu/~vince">Vincent Ng</a>.
                I am broadly interested in <strong>machine learning</strong> and <strong>natural language processing</strong>.
                I have closely worked with <a href="https://howardhsu.github.io/">Hu Xu</a> from <a href="https://ai.facebook.com/">Meta AI</a> and <a href="https://leishu02.github.io/">Lei Shu</a> from <a href="https://research.google/">Google Research</a>.
                During my Ph.D., I worked as a research intern at <a href="https://ai.facebook.com/">Meta AI</a>, <a href="https://www.amazon.science/">Amazon AI</a> and <a href="https://ai.tencent.com/ailab/nlp/en/index.html">Tencent AI Lab</a>.
              </p>
              <p>
                In basic research, I work on <strong>continual and lifelong learning</strong>, <strong>multitask and transfer learning</strong>
                (NeurIPS<a href="https://proceedings.neurips.cc/paper/2020/hash/d7488039246a405baf6a7cbc3613a56f-Abstract.html">20</a>,
                <a href="https://proceedings.neurips.cc/paper/2021/file/bcd0049c35799cdf57d06eaf2eb3cff6-Paper.pdf">21</a>,
                <a href="https://arxiv.org/abs/2211.02633">22</a>).
<!--                 (<a href="https://vincent950129.github.io/">EMNLP22</a>, <a href="\href{https://arxiv.org/pdf/2204.01916}">Preprint</a>).-->
<!--                My research so far has studied-->
<!--                <a href="https://vincent950129.github.io/">Language Model Post-training (Domain-adaptive Pre-training / Pre-finetuning)</a>,-->
<!--                <a href="https://proceedings.neurips.cc/paper/2021/file/bcd0049c35799cdf57d06eaf2eb3cff6-Paper.pdf">Continual Learning in NLP</a>,-->
<!--                <a href="https://proceedings.neurips.cc/paper/2020/hash/d7488039246a405baf6a7cbc3613a56f-Abstract.html">Continual Learning in Image Classification</a>,-->
<!--                <a href="https://www.ijcai.org/proceedings/2019/0879.pdf">and Argument Mining</a>.-->
              </p>
              <p>

               In applied research, I work on various <strong>natural language processing</strong> tasks, such as
                <strong>LM pre-training</strong> (<a href="https://preview.aclanthology.org/emnlp-22-ingestion/2022.emnlp-main.693.pdf">EMNLP22</a>),
                <strong>continual LM pre-training</strong> (<a href="https://openreview.net/forum?id=m_GDIItaI3o">ICLR23</a>, <a href="https://arxiv.org/abs/2210.05549">EMNLP22</a>),
                <strong>continual text classification</strong> (<a href="https://arxiv.org/pdf/2112.03271">NAACL21</a>, <a href="https://arxiv.org/pdf/2112.02714">EMNLP21</a>),
                and <strong>argument mining</strong> (ACL<a href="https://aclanthology.org/P18-1058/">18</a>,<a href="https://aclanthology.org/P19-1390/">19</a>; IJCAI<a href="https://www.ijcai.org/Proceedings/2018/0574.pdf">18</a>,<a href="https://www.ijcai.org/proceedings/2019/0879.pdf">19</a>).
              </p>
              <p>
                My long-term goal is to develop more general and intelligent systems (AGI), making the knowledge in the neural network more reusable and updatable in an ever-changing world.
              </p>

              <p style="text-align:center">
                <a href="mailto:zke4@uic.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=SZ4sFNEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ZixuanKe">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/KeZixuan">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/zixuanke_b.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/zixuanke_b.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
                 <li>(Jan, 2023) To appear in ICLR2023: <a href="https://openreview.net/forum?id=m_GDIItaI3o">Continual Post-Training of Language Models</a>.
                 <li>(November, 2022) New preprint: <a href="https://arxiv.org/abs/2211.12701">Continual Learning of Natural Language Processing Tasks: A Survey</a>.
<!--                 <li>(August, 2022) New preprint: <a href="https://arxiv.org/abs/2208.05516">Quality not quantity: on robustness and dataset design</a> (led by <a href="https://thaonguyen19.github.io/">Thao Nguyen</a>).-->
<!--								 <li>(May, 2022) New preprint: <a href="https://arxiv.org/abs/2205.01397">Data determines distributional robustness</a> (led by Alex Fang).-->
<!--								 <li>(March, 2022) New preprint: <a href="https://arxiv.org/abs/2203.10421">CLIP on Wheels (CoW)</a> (led by <a href="https://sagadre.github.io/">Samir Gadre</a>).-->
<!--								 <li>(March, 2022) New preprint: <a href="https://arxiv.org/abs/2203.05482">Model soups</a>.-->
              </ul>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications &amp Preprints (full list in <a href="https://scholar.google.com/citations?user=SZ4sFNEAAAAJ&hl=en">Google Scholar</a>)</heading>
              <br> (*indicates equal contribution)


              <h3>Preprint</h3>
                <a href="https://arxiv.org/abs/2211.12701">
                  <papertitle>Continual Learning of Natural Language Processing Tasks: A Survey</papertitle>
                </a>
                <br>
                  <strong>Zixuan Ke</strong>,
                  <a href="https://www.cs.uic.edu/~liub/">Bing Liu</a>
                <br>
                <em>Arkiv</em>, 2022
                <br>

              <h3>Language Model Pre-training</h3>

              <p>
                <a href="https://preview.aclanthology.org/emnlp-22-ingestion/2022.emnlp-main.693.pdf">
                  <papertitle>Adapting a Language Model While Preserving its General Knowledge</papertitle>
                </a>
                <br>
                  <strong>Zixuan Ke</strong>,
                  <a href="https://shaoyijia.github.io/">Yijia Shao</a>,
                  <a href="https://linhaowei1.github.io/">Haowei Lin</a>,
                  <a href="https://howardhsu.github.io/">Hu Xu</a>,
                  <a href="https://leishu02.github.io/">Lei Shu</a>,
                  <a href="https://www.cs.uic.edu/~liub/">Bing Liu</a>
                <br>
                <em>EMNLP</em>, 2022
                <br>
                  <a href="https://preview.aclanthology.org/emnlp-22-ingestion/2022.emnlp-main.693.pdf">arxiv</a> /
                  <a href="https://vincent950129.github.io/data/dga.pdf">poster</a> /
                  <a href="https://github.com/UIC-Liu-Lab/DGA">code</a>
              </p>

              <h3>Continual Learning</h3>

                <p>
                <a href="https://arxiv.org/abs/2210.05549">
                  <papertitle>Continual Training of Language Models for Few-Shot Learning</papertitle>
                </a>
                <br>
                  <strong>Zixuan Ke</strong>,
                  <a href="https://linhaowei1.github.io/">Haowei Lin</a>,
                  <a href="https://shaoyijia.github.io/">Yijia Shao</a>,
                  <a href="https://howardhsu.github.io/">Hu Xu</a>,
                  <a href="https://leishu02.github.io/">Lei Shu</a>,
                  <a href="https://www.cs.uic.edu/~liub/">Bing Liu</a>
                <br>
                <em>EMNLP</em>, 2022
                <br>
                  <a href="https://arxiv.org/abs/2210.05549">arxiv</a> /
                  <a href="https://vincent950129.github.io/data/cpt.pdf">poster</a> /
                  <a href="https://github.com/UIC-Liu-Lab/CPT">code</a>
              </p>

              <p>
                <a href="https://proceedings.neurips.cc/paper/2021/file/bcd0049c35799cdf57d06eaf2eb3cff6-Paper.pdf">
                  <papertitle>Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning</papertitle>
                </a>
                <br>
                  <strong>Zixuan Ke</strong>,
                  <a href="https://www.cs.uic.edu/~liub/">Bing Liu</a>,
                  <a href="https://www.linkedin.com/in/nianzu-ma-77b56350">Nianzu Ma</a>,
                  <a href="https://howardhsu.github.io/">Hu Xu</a>,
                  <a href="https://leishu02.github.io/">Lei Shu</a>
                <br>
                <em>NeurIPS</em>, 2021
                <br>
                  <a href="https://arxiv.org/abs/2112.02706">arxiv</a> /
                  <a href="https://slideslive.com/38969013">talk</a> /
                  <a href="https://vincent950129.github.io/data/ctr.pdf">poster</a> /
                  <a href="https://github.com/ZixuanKe/PyContinual">code</a>
                  <iframe src="https://ghbtns.com/github-btn.html?user=zixuanke&repo=PyContinual&type=star&count=true" frameborder="0" scrolling="0" width="110" height="20" title="GitHub" align="bottom" style="position:absolute;Left:30;bottom:-10"></iframe>
<!--                  <iframe src="https://ghbtns.com/github-btn.html?user=zixuanke&repo=PyContinual&type=fork&count=true" frameborder="0" scrolling="0" width="110" height="20" title="GitHub" align="bottom" style="float:right;Left:30;bottom:-10"></iframe>-->

              </p>

              <p>
                <a href="https://proceedings.neurips.cc/paper/2020/hash/d7488039246a405baf6a7cbc3613a56f-Abstract.html">
                  <papertitle>Continual Learning of A Mixed Sequence of Similar and Dissimilar Tasks</papertitle>
                </a>
                <br>
                  <strong>Zixuan Ke</strong>,
                  <a href="https://www.cs.uic.edu/~liub/">Bing Liu</a>,
                  <a href="https://people.mpi-inf.mpg.de/~xhuang/">Xingchang Huang</a>
                <br>
                <em>NeurIPS</em>, 2020
                <br>
                  <a href="https://arxiv.org/abs/2112.10017">arxiv</a> /
                  <a href="https://slideslive.com/38937183">talk</a> /
                  <a href="https://vincent950129.github.io/data/cat.pdf">poster</a> /
                  <a href="https://github.com/ZixuanKe/CAT">code</a>

              </p>

              <h3>Argument Mining</h3>
              <p>
                <a href="https://www.ijcai.org/proceedings/2019/0879.pdf">
                  <papertitle>Automated Essay Scoring: A Survey of the State of the Art</papertitle>
                </a>
                <br>
                  <strong>Zixuan Ke</strong>,
                  <a href="https://www.hlt.utdallas.edu/~vince">Vincent Ng</a>
                <br>
                <em>IJCAI</em>, 2019
              </p>
              <p>
                <a href="https://www.ijcai.org/Proceedings/2018/0574.pdf">
                  <papertitle>Learning to Give Feedback: Modeling Attributes Affecting Argument Persuasiveness in Student Essays</papertitle>
                </a>
                <br>
                  <strong>Zixuan Ke</strong>, Winston Carlile, Nishant Gurrapadi and
                  <a href="https://www.hlt.utdallas.edu/~vince">Vincent Ng</a>
                <br>
                <em>IJCAI</em>, 2018
                <br>
                  <a href="https://www.hlt.utdallas.edu/~zixuan/EssayScoring/">dataset</a>
              </p>
            </td>
          </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Recent Talks &amp Classes &amp Mentorship</heading>
                <p>
              <ul><li> Lifelong and Continual Learning (<a href="https://www.cs.uic.edu/~liub/Part-1-continual-learning-slides.pdf">Part 1</a>, <a href="https://vincent950129.github.io/data/Part-2-continual-learning-slides.pdf">Part 2</a>). A Short PhD Course (8 hours), Aalborg University, June 14 and 16, 2022. (<a href="https://www.cs.uic.edu/~liub/">Bing Liu</a> and <strong>Zixuan Ke</strong>)  </li></ul>
              <ul><li> I'm lucky enough to mentor two students: <a href="https://shaoyijia.github.io/">Yijia Shao (Peking University)</a> and <a href="https://linhaowei1.github.io/">Haowei Lin (Peking University)</a>  </li></ul>

              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Services</heading>

                <p>
                  <ul><li>
                  Program Committee/Reviewer (since 2021):
                    <ul><li> NeurIPS, ICML, ACL, EMNLP, NAACL, IJCAI, ARR, COLING, NLPCC </li></ul>
                  </li></ul>
                </p>
                <p>
                  <ul><li>
                  Journal Reviewer (since 2021):
                    <ul><li> TPAMI, TKDE, Neural Networks, Neurocomputing, Artificial Intelligence,  TALLIP </li></ul>
                  </li></ul>
                </p>
<!--                <p>-->
<!--                  <ul><li>-->
<!--                  Previously, I spent a great year at the Allen Institute for AI with <a href="https://roozbehm.info/index.html">Roozbeh Mottaghi</a>, and interned at-->
<!--                  Apple with <a href="https://mrastegari.github.io/">Mohammad Rastegari</a>.-->
<!--                  </li></ul>-->
<!--                </p>-->
<!--                <p>-->
<!--                  <ul><li>-->
<!--                  I completed my undergraduate thesis in Applied Mathematics at Brown University with senior thesis advisor <a href="https://www.brown.edu/academics/applied-mathematics/faculty/kavita-ramanan/home">Professor Kavita Ramanan</a>.-->
<!--                  Thesis:-->
<!--                  <a href="https://mitchellnw.github.io/data/brown_thesis.pdf">Interacting Particles Systems and Efficient Approximations for Large Sparse Graphs</a>.-->
<!--                  This was my first research experience, for which I am grateful.-->
<!--                  </li></ul>-->
<!--                </p>-->
<!--                <p>-->
<!--                  <ul><li>-->
<!--                  I am from Toronto, Canada and enjoy music, skiing, hiking, camping, reading, and climbing.-->
<!--                  </li></ul>-->
<!--                </p>-->

<!--              Teaching: Pre-doctoral student mentoring-->

<!--              Xinyan (Velocity) Yu, BS->MS at UW (2022‚ÄìCurrent)-->

            </td>
          </tr>
        </tbody></table>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <p style="text-align:right;font-size:small;">
                Template modified from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
